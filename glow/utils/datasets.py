from pathlib import Path

import torch
import torch.nn.functional as F

from torchvision import transforms, datasets


def preprocess(inputs, num_bits = 8):
    """
    Preprocess the images before the Flow-based model.

    Arguments:
    ----------
    inputs: a 4th-order tensor in range [0, 1] of size
        [batch_size, num_channels, image_height, image_width]
        The batch of images to be preprocessed.

    num_bits: int
        The number of bits for quantization. 
        Default: 8
    
    Return:
    -------
    outputs: a 4th-order tensor in range [-0.5, 0.5] of size
        [batch_size, num_channels, image_height, image_width]
        The batch of images after preprocessing.

    """
    inputs = inputs * 255

    num_bins = 2 ** num_bits

    if num_bits < 8:
        inputs = torch.floor(inputs / (2 ** (8 - num_bits)))

    outputs = inputs / num_bins - 0.5

    return outputs
    

def postprocess(inputs, num_bits = 8):
    """
    Postprocess the images generated by the Flow-based model.

    Arguments:
    ----------
    inputs: a 4th-order tensor in range [-inf, int] of size
        [batch_size, num_channels, image_height, image_width]
        The batch of images to be postprocessed.

    num_bits: int
        The number of bits for quantization.
        Default: 8

    Return:
    -------
    outputs: a 4th-order tensor in range [0, 255] of size
        [batch_size, num_channels, image_height, image_width]
        The batch of images after postprocessing.

    """
    outputs = (torch.clamp(inputs, -0.5, 0.5) + 0.5) * 255

    if num_bits < 8:
        outputs = torch.floor(outputs / (2 ** (8 - num_bits))) * (2 ** (8 - num_bits)) 

    return outputs.byte()


def get_CIFAR10(augment, dataroot, download = False):
    """

    """
    image_shape, num_classes = (32, 32, 3), 10

    basic_transform = [transforms.ToTensor(), preprocess]
    valid_transform = transforms.Compose(basic_transform)

    train_transform = []

    if augment:
        train_transform.extend([
            transforms.RandomAffine(0, translate = (0.1, 0.1)),
            transforms.RandomHorizontalFlip()
        ])

    train_transform.extend(basic_transform)
    train_transform = transforms.Compose(train_transform)

    one_hot_encode = lambda target: F.one_hot(torch.tensor(target), num_classes)

    path = Path(dataroot) / "datasets" / "CIFAR10"

    train_dataset = datasets.CIFAR10(path, train = True,
        transform = train_transform, target_transform = one_hot_encode, download = download)

    valid_dataset = datasets.CIFAR10(path, train = False,
        transform = valid_transform,  target_transform = one_hot_encode, download = download)

    return image_shape, num_classes, train_dataset, valid_dataset


def get_SVHN(augment, dataroot, download = False):
    """

    """
    image_shape, num_classes = (32, 32, 3), 10

    basic_transform = [transforms.ToTensor(), preprocess]
    valid_transform = transforms.Compose(basic_transform)

    train_transform = []

    if augment:
        train_transform.extend([transforms.RandomAffine(0, translate = (0.1, 0.1))])

    train_transform.extend(basic_transform)
    train_transform = transforms.Compose(train_transform)

    one_hot_encode = lambda target: F.one_hot(torch.tensor(target), num_classes)

    path = Path(dataroot) / "datasets" / "SVHN"

    train_dataset = datasets.SVHN(path, split = "train", 
        transform = train_transform, target_transform = one_hot_encode, download = download)

    valid_dataset = datasets.SVHN(path, split = "test",
        transform = valid_transform, target_transform = one_hot_encode, download = download)

    return image_shape, num_classes, train_dataset, valid_dataset


def get_MNIST(augment, dataroot, download = False):
    """

    """
    image_shape, num_classes = (28, 28, 1), 10

    basic_transform = [transforms.ToTensor(), preprocess]
    valid_transform = transforms.Compose(basic_transform)

    train_transform = []

    if augment:
        train_transform.extend([transforms.RandomAffine(0, translate = (0.1, 0.1))])

    train_transform.extend(basic_transform)
    train_transform = transforms.Compose(train_transform)

    one_hot_encode = lambda target: F.one_hot(torch.tensor(target), num_classes)

    path = Path(dataroot) / "datasets" / "MNIST"

    train_dataset = datasets.MNIST(path, train = True,
        transform = train_transform, target_transform = one_hot_encode, download = download)

    valid_dataset = datasets.MNIST(path, train = False,
        transform = valid_transform, target_transform = one_hot_encode, download = download)

    return image_shape, num_classes, train_dataset, valid_dataset


def get_FashionMNIST(augment, dataroot, download = False):
    """

    """
    image_shape, num_classes = (28, 28, 1), 10

    basic_transform = [transforms.ToTensor(), preprocess]
    valid_transform = transforms.Compose(basic_transform)

    train_transform = []

    if augment:
        train_transform.extend([
            transforms.RandomAffine(0, translate = (0.1, 0.1)),
            transforms.RandomHorizontalFlip()
        ])

    train_transform.extend(basic_transform)
    train_transform = transforms.Compose(train_transform)

    one_hot_encode = lambda target: F.one_hot(torch.tensor(target), num_classes)

    path = Path(dataroot) / "datasets" / "FashionMNIST"

    train_dataset = datasets.FashionMNIST(path, train = True,
        transform = train_transform, target_transform = one_hot_encode, download = download)

    valid_dataset = datasets.FashionMNIST(path, train = False,
        transform = valid_transform, target_transform = one_hot_encode, download = download)

    return image_shape, num_classes, train_dataset, valid_dataset


def check_dataset(dataset, dataroot, augment, download):
    """
    Wrapper for different datasets.

    Arguments:
    ----------
    dataset: str
        The dataset used for training.
        Options: "SVHN", "CIFAR10", "MNIST", or "FashionMNIST".

    dataroot: str
        The path to the root folder storing the datasets.

    augment: bool
        Whether to use data augmentation for the training set.

    download: bool 
        Whether to download the dataset online.

    Returns:
    --------
    image_shape: a tuple of (image_height, )
        The image format of the dataset. 

    num_classes: int
        The number of classes in the dataset.

    train_dataset, valid_dataset: torchvision.Dataset objects
        The training and validation sets in the dataset. 
    
    """
    if dataset == "SVHN":
        get_dataset = get_SVHN
    elif dataset == "CIFAR10":
        get_dataset = get_CIFAR10
    elif dataset == "MNIST":
        get_dataset = get_MNIST
    elif dataset == "FashionMNIST":
        get_dataset = get_FashionMNIST
    else: # if dataset not in above
        raise NotImplementedError

    return get_dataset(augment, dataroot, download)
